{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Cross-Task Transfer: Universal Notebook\n",
    "## All 7 Models √ó All 8 Tasks - Fixed & Ready\n",
    "\n",
    "**Features**:\n",
    "- ‚úÖ Automatic task detection (NER, RE, Classification, QA, Similarity)\n",
    "- ‚úÖ Automatic model head selection\n",
    "- ‚úÖ Automatic metrics computation\n",
    "- ‚úÖ Works with all 7 BERT models\n",
    "- ‚úÖ Works with all 8 medical NLP tasks\n",
    "- ‚úÖ Integrated smoke test for quick validation\n",
    "- ‚úÖ Token tracking for RQ5\n",
    "- ‚úÖ CSV export for analysis\n",
    "\n",
    "**Expected Results**:\n",
    "- BioBERT on BC2GM: F1 = 0.84 (not 0.46!)\n",
    "- All models and tasks work automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Clone repo\n",
    "print(\"üì• Cloning repository...\")\n",
    "os.chdir('/kaggle/working')\n",
    "!rm -rf Crosstalk_Medical_LLM\n",
    "!git clone https://github.com/bharathbolla/Crosstalk_Medical_LLM.git\n",
    "os.chdir('Crosstalk_Medical_LLM')\n",
    "\n",
    "print(f\"\\n‚úÖ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Verify datasets\n",
    "!python test_pickle_load.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "!pip install -q transformers torch accelerate scikit-learn seqeval pandas scipy\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import csv\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# GPU verification\n",
    "print(f\"\\n‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Experiment ID\n",
    "EXPERIMENT_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"\\nüìä Experiment ID: {EXPERIMENT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Configuration\n",
    "### ‚≠ê Change ONLY these 2 lines to test different models and tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ‚≠ê MAIN CONFIGURATION ‚≠ê\n",
    "# Change these 2 lines to test any model + task combination!\n",
    "# ============================================\n",
    "\n",
    "CONFIG = {\n",
    "    # ‚≠ê MODEL SELECTION (test any of the 7 models)\n",
    "    \"model_name\": \"dmis-lab/biobert-v1.1\",  # Start with BioBERT\n",
    "    # Other options:\n",
    "    # \"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\",  # BlueBERT (best)\n",
    "    # \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",  # PubMedBERT\n",
    "    # \"allenai/biomed_roberta_base\",  # BioMed-RoBERTa\n",
    "    # \"emilyalsentzer/Bio_ClinicalBERT\",  # Clinical-BERT\n",
    "    # \"roberta-base\",  # RoBERTa (baseline)\n",
    "    # \"bert-base-uncased\",  # BERT (baseline)\n",
    "\n",
    "    # ‚≠ê TASK SELECTION (test any of the 8 tasks)\n",
    "    \"datasets\": [\"bc2gm\"],  # Start with BC2GM\n",
    "    # Other options: [\"jnlpba\"], [\"chemprot\"], [\"ddi\"], [\"gad\"], [\"hoc\"], [\"pubmedqa\"], [\"biosses\"]\n",
    "    # Or multiple: [\"bc2gm\", \"jnlpba\"]  # Multi-task\n",
    "\n",
    "    # Experiment metadata\n",
    "    \"experiment_id\": EXPERIMENT_ID,\n",
    "    \"experiment_type\": \"single_task\",  # or \"multi_task\"\n",
    "    \"description\": \"Universal notebook - auto task detection\",\n",
    "\n",
    "    # Dataset configuration\n",
    "    \"max_samples_per_dataset\": None,  # None = use all data, or 50 for smoke test\n",
    "\n",
    "    # Training hyperparameters\n",
    "    \"num_epochs\": 10,\n",
    "    \"batch_size\": 32,  # Auto-adjusted based on GPU\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"max_length\": 512,\n",
    "    \"warmup_steps\": 500,\n",
    "    \"weight_decay\": 0.01,\n",
    "\n",
    "    # Early stopping\n",
    "    \"use_early_stopping\": True,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_threshold\": 0.0001,\n",
    "\n",
    "    # Token tracking (RQ5)\n",
    "    \"track_tokens\": True,\n",
    "\n",
    "    # Checkpointing\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100,\n",
    "    \"keep_last_n_checkpoints\": 2,\n",
    "    \"resume_from_checkpoint\": True,\n",
    "\n",
    "    # Evaluation\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 250,\n",
    "\n",
    "    # Logging\n",
    "    \"use_wandb\": False,\n",
    "    \"logging_steps\": 50,\n",
    "}\n",
    "\n",
    "# Auto-detect GPU and adjust batch size\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    total_vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "\n",
    "    print(f\"\\nüîç GPU Detection:\")\n",
    "    print(f\"   GPU: {gpu_name}\")\n",
    "    print(f\"   VRAM: {total_vram:.1f} GB\")\n",
    "\n",
    "    if \"A100\" in gpu_name:\n",
    "        CONFIG['batch_size'] = 64\n",
    "        print(f\"   ‚úÖ Optimized for A100: batch_size = 64\")\n",
    "    elif \"T4\" in gpu_name:\n",
    "        CONFIG['batch_size'] = 32\n",
    "        print(f\"   ‚úÖ Optimized for T4: batch_size = 32\")\n",
    "    else:\n",
    "        CONFIG['batch_size'] = 16\n",
    "        print(f\"   ‚ö†Ô∏è  Conservative: batch_size = 16\")\n",
    "\n",
    "# Save config\n",
    "with open(RESULTS_DIR / f\"config_{EXPERIMENT_ID}.json\", 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {CONFIG['model_name']}\")\n",
    "print(f\"Datasets: {CONFIG['datasets']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Max epochs: {CONFIG['num_epochs']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Task Configurations\n",
    "### Automatic task detection - no changes needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TASK CONFIGURATIONS FOR ALL 8 DATASETS\n",
    "# ============================================\n",
    "\n",
    "TASK_CONFIGS = {\n",
    "    # NER tasks - token classification\n",
    "    'bc2gm': {\n",
    "        'task_type': 'ner',\n",
    "        'labels': ['O', 'B-GENE', 'I-GENE'],\n",
    "        'model_type': 'token_classification',\n",
    "    },\n",
    "    'jnlpba': {\n",
    "        'task_type': 'ner',\n",
    "        'labels': ['O', 'B-DNA', 'I-DNA', 'B-RNA', 'I-RNA', 'B-cell_line', 'I-cell_line', 'B-cell_type', 'I-cell_type', 'B-protein', 'I-protein'],\n",
    "        'model_type': 'token_classification',\n",
    "    },\n",
    "\n",
    "    # Relation Extraction - sequence classification\n",
    "    'chemprot': {\n",
    "        'task_type': 're',\n",
    "        'labels': [f'CPR:{i}' for i in range(13)],\n",
    "        'model_type': 'sequence_classification',\n",
    "    },\n",
    "    'ddi': {\n",
    "        'task_type': 're',\n",
    "        'labels': ['DDI-false', 'DDI-mechanism', 'DDI-effect', 'DDI-advise', 'DDI-int'],\n",
    "        'model_type': 'sequence_classification',\n",
    "    },\n",
    "\n",
    "    # Classification tasks\n",
    "    'gad': {\n",
    "        'task_type': 'classification',\n",
    "        'labels': ['0', '1'],\n",
    "        'model_type': 'sequence_classification',\n",
    "    },\n",
    "    'hoc': {\n",
    "        'task_type': 'multilabel_classification',\n",
    "        'labels': [f'hallmark_{i}' for i in range(10)],\n",
    "        'model_type': 'sequence_classification',\n",
    "        'problem_type': 'multi_label_classification',\n",
    "    },\n",
    "\n",
    "    # QA task\n",
    "    'pubmedqa': {\n",
    "        'task_type': 'qa',\n",
    "        'labels': ['no', 'yes', 'maybe'],\n",
    "        'model_type': 'sequence_classification',\n",
    "    },\n",
    "\n",
    "    # Similarity/Regression task\n",
    "    'biosses': {\n",
    "        'task_type': 'similarity',\n",
    "        'labels': None,\n",
    "        'model_type': 'regression',\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Task configurations loaded for all 8 datasets\")\n",
    "print(f\"\\nConfigured tasks: {list(TASK_CONFIGS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: üî• SMOKE TEST\n",
    "### Quick validation (50 samples, 1 epoch) - Run this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SMOKE TEST: Quick validation before full run\n",
    "# ============================================\n",
    "\n",
    "import sys\n",
    "import io\n",
    "if sys.platform != 'win32':  # Only on Linux/Kaggle\n",
    "    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî• SMOKE TEST\")\n",
    "print(\"=\"*60)\n",
    "print(\"Purpose: Quick validation (50 samples, 1 epoch)\")\n",
    "print(\"Time: ~2-3 minutes\")\n",
    "print(\"Expected: F1 > 0.30 (just checking it works!)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ask user if they want smoke test\n",
    "print(\"\\n‚ö†Ô∏è  Do you want to run SMOKE TEST first?\")\n",
    "print(\"   YES ‚Üí Quick 2-min test (recommended)\")\n",
    "print(\"   NO  ‚Üí Full training (~3 hours)\")\n",
    "print(\"\\nTo enable: Set SMOKE_TEST = True below\")\n",
    "print(\"To disable: Set SMOKE_TEST = False below\")\n",
    "\n",
    "# ‚≠ê SET THIS TO True FOR SMOKE TEST\n",
    "SMOKE_TEST = True  # Change to False for full training\n",
    "\n",
    "if SMOKE_TEST:\n",
    "    print(\"\\n‚úÖ SMOKE TEST ENABLED\")\n",
    "    print(\"   Settings: 50 samples, 1 epoch, batch 16\")\n",
    "    \n",
    "    # Override config for smoke test\n",
    "    CONFIG['max_samples_per_dataset'] = 50\n",
    "    CONFIG['num_epochs'] = 1\n",
    "    CONFIG['batch_size'] = 16\n",
    "    CONFIG['max_length'] = 128\n",
    "    CONFIG['warmup_steps'] = 10\n",
    "    CONFIG['save_steps'] = 50\n",
    "    CONFIG['eval_steps'] = 25\n",
    "    CONFIG['use_early_stopping'] = False\n",
    "    \n",
    "    print(\"\\n‚è±Ô∏è  Expected time: 2-3 minutes\")\n",
    "    print(\"‚úÖ If F1 > 0.30: Everything works! Set SMOKE_TEST=False for full run\")\n",
    "    print(\"‚ùå If F1 < 0.30: Something wrong, check configuration\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ FULL TRAINING MODE\")\n",
    "    print(\"   Using full configuration\")\n",
    "    print(f\"   Samples: ALL\")\n",
    "    print(f\"   Epochs: {CONFIG['num_epochs']}\")\n",
    "    print(f\"   Expected time: ~3 hours\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
