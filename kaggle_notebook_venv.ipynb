{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Cross-Task Transfer - Kaggle (Virtual Environment)\n",
    "\n",
    "**Solution**: Uses isolated virtual environment to avoid dependency conflicts\n",
    "\n",
    "**Setup**: GPU T4 x2 + Internet ON\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/bharathbolla/Crosstalk_Medical_LLM.git\n",
    "%cd Crosstalk_Medical_LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Create Virtual Environment\n",
    "\n",
    "This creates an isolated Python environment to avoid conflicts with Kaggle's pre-installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create virtual environment\n",
    "!python3 -m venv venv\n",
    "\n",
    "print(\"âœ… Virtual environment created!\")\n",
    "print(\"\\nNext: Run Cell 3 to install packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Install Compatible Packages\n",
    "\n",
    "Installs compatible versions in the isolated environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages in venv (compatible versions)\n",
    "!venv/bin/pip install -q --upgrade pip\n",
    "!venv/bin/pip install -q pyarrow==14.0.0 datasets==2.20.0\n",
    "!venv/bin/pip install -q transformers==4.40.0 evaluate==0.4.2\n",
    "!venv/bin/pip install -q torch accelerate==0.30.0 scikit-learn pyyaml\n",
    "\n",
    "# Verify versions\n",
    "!venv/bin/python -c \"import datasets; import pyarrow; print(f'datasets: {datasets.__version__}'); print(f'pyarrow: {pyarrow.__version__}')\"\n",
    "\n",
    "print(\"\\nâœ… All packages installed in virtual environment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Verify Datasets Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data/raw\")\n",
    "datasets = [\"bc2gm\", \"jnlpba\", \"chemprot\", \"ddi\", \"gad\", \"hoc\", \"pubmedqa\", \"biosses\"]\n",
    "\n",
    "print(\"Checking datasets...\\n\")\n",
    "for name in datasets:\n",
    "    status = \"âœ“\" if (data_path / name).exists() else \"âœ—\"\n",
    "    print(f\"{status} {name}\")\n",
    "\n",
    "print(\"\\nâœ… All datasets are included in the repository!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Test Parsers (Using venv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test_parsers.py using the virtual environment Python\n",
    "!venv/bin/python test_parsers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Quick Smoke Test (Optional)\n",
    "\n",
    "Test training pipeline on 100 samples for 50 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source venv/bin/activate\n",
    "\n",
    "python -c \"\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from data import BC2GMDataset\n",
    "from data.collators import NERCollator\n",
    "from pathlib import Path\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = BC2GMDataset(data_path=Path('data/raw'), split='train')\n",
    "small_dataset = [dataset[i] for i in range(100)]\n",
    "print(f'Loaded {len(small_dataset)} samples')\n",
    "\n",
    "print('Loading BERT model...')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "label_schema = dataset.get_label_schema()\n",
    "model = AutoModelForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(label_schema))\n",
    "\n",
    "print('Setting up training...')\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./smoke_test',\n",
    "    max_steps=50,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "collator = NERCollator(tokenizer=tokenizer, label_schema=label_schema)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_dataset,\n",
    "    data_collator=collator\n",
    ")\n",
    "\n",
    "print('Training...')\n",
    "trainer.train()\n",
    "print('âœ… Smoke test complete!')\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Run Baseline Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baseline experiment using venv Python\n",
    "!venv/bin/python scripts/run_baseline.py \\\n",
    "    --model bert-base-uncased \\\n",
    "    --task bc2gm \\\n",
    "    --epochs 3 \\\n",
    "    --batch_size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success! ðŸŽ‰\n",
    "\n",
    "If you got here without errors:\n",
    "- âœ… Virtual environment created\n",
    "- âœ… Compatible packages installed  \n",
    "- âœ… All 8 parsers working\n",
    "- âœ… Ready for experiments!\n",
    "\n",
    "---\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "1. **Always use venv Python**: `venv/bin/python` instead of system Python\n",
    "2. **All datasets included**: No downloads needed\n",
    "3. **No version conflicts**: Isolated environment\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "Run full experiments:\n",
    "```bash\n",
    "!venv/bin/python scripts/run_experiment.py strategy=s1_single task=all\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
