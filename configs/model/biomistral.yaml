model:
  name: "BioMistral/BioMistral-7B"
  short_name: "biomistral"
  params: 7.2e9

  quantization:
    enabled: true  # QLoRA required for T4
    bits: 4
    quant_type: "nf4"
    compute_dtype: "float16"
    double_quant: true

  lora:
    rank: 32
    alpha: 64
    dropout: 0.05
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]

  training:
    max_batch_size_t4: 4
    gradient_checkpointing: true
    flash_attention: true

  unsloth:
    compatible: false
    use_for: []
